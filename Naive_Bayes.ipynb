{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_1():\n",
    "    feature_name = ['年龄','有工作','有房','信贷情况']\n",
    "    dataset = [['青年','否','否','一般','否']]\n",
    "    dataset.append(['青年','否','否','好','否'])\n",
    "    dataset.append(['青年','是','否','好','是'])\n",
    "    dataset.append(['青年','是','是','一般','是'])\n",
    "    dataset.append(['青年','否','否','一般','否'])\n",
    "    dataset.append(['中年','否','否','一般','否'])\n",
    "    dataset.append(['中年','否','否','好','否'])\n",
    "    dataset.append(['中年','是','是','好','是'])\n",
    "    dataset.append(['中年','否','是','非常好','是'])\n",
    "    dataset.append(['中年','否','是','非常好','是'])\n",
    "    dataset.append(['老年','否','是','非常好','是'])\n",
    "    dataset.append(['老年','否','是','好','是'])\n",
    "    dataset.append(['老年','是','否','好','是'])\n",
    "    dataset.append(['老年','是','否','非常好','是'])\n",
    "    dataset.append(['老年','否','否','一般','否'])\n",
    "    dataset = np.array(dataset)\n",
    "    return dataset, feature_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_2():\n",
    "    feature = load_iris().data\n",
    "    label = load_iris().target.reshape(-1, 1)\n",
    "    iris_name = load_iris().feature_names\n",
    "    iris = np.concatenate((feature, label), axis = 1)\n",
    "    return iris, iris_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_calculation(dataset):\n",
    "    values = []\n",
    "    for i in range(dataset.shape[1]):\n",
    "        value = np.unique(dataset[:, i])\n",
    "        values.append(value)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_prob(dataset):\n",
    "    label_values = np.unique(dataset[:,-1])\n",
    "    subdata = {}\n",
    "    prob = {}\n",
    "    N = len(label_values)\n",
    "    #根据label取的值将数据集分成几个类， 并计算每个类的概率\n",
    "    for valu in label_values:\n",
    "        subdata[valu] = dataset[dataset[:, -1] == valu]\n",
    "        prob[valu] = (len(subdata[valu])+1)/(len(dataset)+N)\n",
    "        \n",
    "    return subdata, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(dataset, feature_name, distribution):\n",
    "    '''\n",
    "    构建多重字典，计算各个特征的概率分布\n",
    "    对于连续特征，假设为正态分布，计算均值和标准差\n",
    "    对于类别特征，假设为伯努利分布，计算每个类别的概率\n",
    "    \n",
    "    '''\n",
    "    values = value_calculation(dataset)\n",
    "    subdata, label_prob = class_prob(dataset)\n",
    "    label_key = list(label_prob.keys())\n",
    "    prob_dict = {}\n",
    "    \n",
    "    #按标签值不同将数据集分为几部分\n",
    "    for num, data in enumerate(subdata.values()):\n",
    "        count = len(data)\n",
    "        data_prob = {}\n",
    "        \n",
    "        #对于类别特征，计算每部分数据中该特征取不同值时的条件概率\n",
    "        feat_count = len(data[0,:])-1\n",
    "        for i in range(feat_count):\n",
    "            feat_value = values[i]\n",
    "            n = len(feat_value)\n",
    "            feat_prob = {}\n",
    "            \n",
    "            if distribution == 'bernoulli':\n",
    "                for valu in feat_value:\n",
    "                    prob = (np.sum(data[:, i] == valu)+1) / (count+n)\n",
    "                    feat_prob[valu] = prob\n",
    "                \n",
    "            elif distribution == 'normal':\n",
    "                feat_prob['mean'] = np.mean(data[:,i])\n",
    "                feat_prob['std'] = np.std(data[:, i])\n",
    "                \n",
    "            else:\n",
    "                raise Exception('distribution == normal or bernoulli')\n",
    "                \n",
    "            data_prob[feature_name[i]] = feat_prob\n",
    "        prob_dict[label_key[num]] = data_prob\n",
    "        \n",
    "    return prob_dict, label_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_prob_density(mean, sd, x):\n",
    "    prob = 1/(np.sqrt(2*np.pi) * sd) * np.exp(-0.5 * (np.square(x - mean)) / np.square(sd))    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, feature_name, model, label_prob, distribution):\n",
    "    results = []\n",
    "    \n",
    "    for example in X:\n",
    "        max_prob = 0.\n",
    "\n",
    "        #计算每个样本取每个标签值的概率\n",
    "        for label in list(model.keys()):\n",
    "            prob = 1.\n",
    "        \n",
    "            for i, name in enumerate(feature_name):\n",
    "                valu = example[i]\n",
    "                \n",
    "                if distribution == 'bernoulli':\n",
    "                #简单起见，如果测试样本中出现训练集特定标签的子集下没有的值，将概率设为1e-3，当然也可以用拉普拉斯平滑设置基准数\n",
    "                    if valu not in model[label][name].keys():\n",
    "                        feat_prob = 1e-4\n",
    "                    else:\n",
    "                        feat_prob = model[label][name][valu] * label_prob[label]\n",
    "                        \n",
    "                elif distribution == 'normal':\n",
    "                    mean = model[label][name]['mean']\n",
    "                    sd = model[label][name]['std']\n",
    "                    feat_prob = normal_prob_density(mean, sd, valu) * label_prob[label]\n",
    "                \n",
    "                else:\n",
    "                    raise Exception('distribution == normal or bernoulli')\n",
    "                        \n",
    "                #将每个特征的概率连乘得到最终概率\n",
    "                prob = prob * feat_prob\n",
    "\n",
    "            #选出最大的概率值，并返回此时的标签作为预测结果\n",
    "            if prob >= max_prob:\n",
    "                max_prob = prob\n",
    "                result = label\n",
    "\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(data):\n",
    "    if data == 'iris':\n",
    "        dataset, feature_name = load_data_2()\n",
    "        model, label_prob = naive_bayes(dataset, feature_name, 'normal')\n",
    "        pred = predict(dataset[:, :4], feature_name, model, label_prob, 'normal')\n",
    "        \n",
    "    elif data == 'loan':\n",
    "        dataset, feature_name = load_data_1()\n",
    "        model, label_prob = naive_bayes(dataset, feature_name, 'bernoulli')\n",
    "        pred = predict(dataset[:, :4], feature_name, model, label_prob, 'bernoulli')\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['否', '否', '是', '是', '否', '否', '是', '是', '是', '是', '是', '是', '是', '是', '否']\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    result1 = main('loan')\n",
    "    result2 = main('iris')\n",
    "    print(result1)\n",
    "    print(result2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
