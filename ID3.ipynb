{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算数据集的整体信息熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 计算每一个标签值的个数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 计算每个标签值的出现频率  pi = label[i] / count(label) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 计算信息熵 Entropy = sum(-pi * log(pi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_count_calculation(dataset):\n",
    "    label_count = {}                             #计算每个标签值的个数\n",
    "    for data in dataset:                   #遍历每一个数据\n",
    "        value = data[-1]                   #取出每一行数据的最后一个值作为标签值\n",
    "        if value not in label_count.keys():      #将标签值作为字典的键，出现次数作为字典的值，计算每一个标签值的个数\n",
    "            label_count[value] = 1\n",
    "        else:\n",
    "            label_count[value] += 1\n",
    "    return label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_calculation(dataset):\n",
    "    '''\n",
    "    count： 字典，key为各个不同的标签值，value为各个标签值出现的次数\n",
    "    p： 每个标签值出现的频率组成的列表\n",
    "    entropy：信息熵\n",
    "    '''\n",
    "    count = label_count_calculation(dataset)\n",
    "    dataset_count = len(dataset)\n",
    "    p = []\n",
    "\n",
    "    entropy = 0.\n",
    "    for val in count.values():             #遍历count中的每一个值，即每一个标签值的个数\n",
    "        pi = val/dataset_count \n",
    "        entropy_pi = -pi * log2(pi)        #计算信息熵\n",
    "        entropy += entropy_pi\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算信息增益"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 计算不同特征值的个数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 依次取出每个特征值所包含数据的行标，并分别组成不同的小数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 计算分割后的数据集占总数据集的比例 p_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 用gain_calculation循环计算每个特征下每个取值的信息增益，并返回最大信息增益"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_entropy(dataset, feat, value):\n",
    "    data_1 = []\n",
    "    data_2 = []\n",
    "    \n",
    "    for index in dataset:\n",
    "        if index[feat] == value:\n",
    "            data_1.append(index)\n",
    "        else:\n",
    "            data_2.append(index)\n",
    "    p_data = len(data_1)/len(dataset)\n",
    "    \n",
    "    result = entropy_calculation(data_1) * p_data\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_calculation(dataset):\n",
    "    '''\n",
    "    n：特征数\n",
    "    dataset_entropy：数据集信息熵\n",
    "    max_gain：最大信息增益\n",
    "    max_feature：得到最大信息增益的特征索引\n",
    "    feature_values：max_feature特征下的取值\n",
    "    '''\n",
    "    n = len(dataset[0])-1\n",
    "    dataset_entropy = entropy_calculation(dataset)\n",
    "    max_gain = 0.\n",
    "\n",
    "    for feat in range(n):\n",
    "\n",
    "        #计算每个特征下的取值\n",
    "        values = list(set(example[feat] for example in dataset))\n",
    "        feature_gain = dataset_entropy\n",
    "        for valu in values:\n",
    "            entropy = data_entropy(dataset, feat, valu)\n",
    "            feature_gain -= entropy\n",
    "\n",
    "        if feature_gain > max_gain:\n",
    "            max_gain = feature_gain\n",
    "            best_feature = feat\n",
    "            feature_values = values\n",
    "\n",
    "    return best_feature, feature_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_rate_calculation(dataset):\n",
    "    '''\n",
    "    n：特征数\n",
    "    dataset_entropy：数据集信息熵\n",
    "    max_gain_rate：最大信息增益率\n",
    "    max_feature：得到最大信息增益率的特征索引\n",
    "    feature_values：max_feature特征下的取值\n",
    "    '''\n",
    "    n = len(dataset[0])-1\n",
    "    dataset_entropy = entropy_calculation(dataset)\n",
    "    max_gain_rate = 0.\n",
    "\n",
    "    for feat in range(n):\n",
    "\n",
    "        #计算每个特征下的取值\n",
    "        values = list(set(example[feat] for example in dataset))\n",
    "        feature_gain = dataset_entropy\n",
    "        for valu in values:\n",
    "            entropy = data_entropy(dataset, feat, valu)\n",
    "            feature_gain -= entropy\n",
    "        feature_gain_rate = feature_gain/len(values)\n",
    "\n",
    "        if feature_gain_rate > max_gain_rate:\n",
    "            max_gain_rate = feature_gain_rate\n",
    "            best_feature = feat\n",
    "            feature_values = values\n",
    "\n",
    "    return best_feature, feature_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_calculation(dataset):\n",
    "    '''\n",
    "    min_gini：最小信息增益\n",
    "    best_feature：获得最小基尼指数的特征\n",
    "    best_feat_valu：获得最小基尼指数的特征取值\n",
    "    '''\n",
    "    n = len(dataset[0]) - 1\n",
    "    min_gini = 1.\n",
    "    \n",
    "    for feat in range(n):\n",
    "        values = list(set(example[feat] for example in dataset))\n",
    "        \n",
    "        for valu in values:\n",
    "            gini = data_entropy(dataset, feat, valu, 'CART')\n",
    "            \n",
    "            if gini < min_gini:\n",
    "                min_gini = gini\n",
    "                best_feature = feat\n",
    "                best_feat_valu = valu\n",
    "                \n",
    "    return best_feature, best_feat_valu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tree(dataset, axis, value):\n",
    "\n",
    "    subtree = []          #分裂后的子树\n",
    "    for feat in dataset:\n",
    "        if feat[axis] == value:\n",
    "            data = feat[:axis]\n",
    "            data.extend(feat[axis+1:])\n",
    "            subtree.append(data)\n",
    "    return subtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote(dataset):\n",
    "    labelcount = label_count_calculation(dataset)\n",
    "    class_predict = max(labelcount)\n",
    "    return class_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tree(dataset, feature_name, criterion):\n",
    "    #计算出子树所包含的标签字典\n",
    "    label_count = label_count_calculation(dataset)\n",
    "    \n",
    "    #如果子树中标签值全部相同，返回该标签值\n",
    "    if len(label_count) == 1:\n",
    "        return list(label_count.keys())[0]\n",
    "    \n",
    "    if len(dataset[0]) == 1:                                 \n",
    "        # 当只剩一个特征时，返回标签值\n",
    "        return max(vote(dataset))\n",
    "    \n",
    "    #根据不同算法获取特征索引和特征值（去重）\n",
    "    if criterion == 'ID3':\n",
    "        best_feature, feature_values = gain_calculation(dataset)\n",
    "    elif criterion == 'C4.5':\n",
    "        best_feature, feature_values = gain_rate_calculation(dataset)\n",
    "    else:\n",
    "        raise ValueError('criterion input error')\n",
    "        \n",
    "    #获取特征名字，并在原feature_name中删除该特征名字\n",
    "    #记录一个坑，这里如果用del删除的话会连同feature_name一起修改\n",
    "    name = feature_name[best_feature]\n",
    "    new_name = feature_name[:best_feature]\n",
    "    new_name.extend(feature_name[best_feature+1:])\n",
    "    \n",
    "    #将信息增益最大的特征索引用于构建决策树字典的键\n",
    "    mytree = {name:{}}\n",
    "    for valu in feature_values:\n",
    "        subtree = split_tree(dataset, best_feature, valu)\n",
    "        if not subtree:\n",
    "            continue\n",
    "\n",
    "        mytree[name][valu] = create_tree(subtree, new_name, criterion)\n",
    "    return mytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(tree, data, feat_name):\n",
    "    print(tree)\n",
    "    if type(tree) != dict:\n",
    "        return tree\n",
    "    else:\n",
    "        for i, key in enumerate(feat_name):\n",
    "            if key in tree.keys():\n",
    "                \n",
    "                if len(tree[key]) == 1:\n",
    "                    return list(tree.values())[0]\n",
    "                else:\n",
    "                    \n",
    "                    new_tree = tree[key][data[i]]\n",
    "                    return classify(new_tree, data, feat_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'有房': {'否': {'有工作': {'否': '否', '是': '是'}}, '是': '是'}}\n",
      "{'有工作': {'否': '否', '是': '是'}}\n",
      "是\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    feature_name = ['年龄','有工作','有房','信贷情况']\n",
    "\n",
    "    dataset = [['青年','否','否','一般','否']]\n",
    "    dataset.append(['青年','否','否','好','否'])\n",
    "    dataset.append(['青年','是','否','好','是'])\n",
    "    dataset.append(['青年','是','是','一般','是'])\n",
    "    dataset.append(['青年','否','否','一般','否'])\n",
    "    dataset.append(['中年','否','否','一般','否'])\n",
    "    dataset.append(['中年','否','否','好','否'])\n",
    "    dataset.append(['中年','是','是','好','是'])\n",
    "    dataset.append(['中年','否','是','非常好','是'])\n",
    "    dataset.append(['中年','否','是','非常好','是'])\n",
    "    dataset.append(['老年','否','是','非常好','是'])\n",
    "    dataset.append(['老年','否','是','好','是'])\n",
    "    dataset.append(['老年','是','否','好','是'])\n",
    "    dataset.append(['老年','是','否','非常好','是'])\n",
    "    dataset.append(['老年','否','否','一般','否'])\n",
    "\n",
    "\n",
    "    data = ['青年','是','否','一般']\n",
    "    mytree = create_tree(dataset, feature_name, 'ID3')\n",
    "    result = classify(mytree, data, feature_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
